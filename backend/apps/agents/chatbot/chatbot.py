"""
LangGraph-based Chatbot Implementation with RAG as a Tool

This module implements a chatbot using LangGraph where RAG functionality 
is implemented as a tool, and other responses are generated by the LLM
using system prompts.
"""

import logging
from typing import Dict, Any, Optional, List
from datetime import datetime
from django.contrib.auth.models import User
from django.db import connection, transaction
import time

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, MessagesState
from langgraph.graph.state import CompiledStateGraph
from langgraph.checkpoint.postgres import PostgresSaver
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import tools_condition, ToolNode

from ..kg_constructor.config import get_openai_llm
from ..kg_constructor.neo4j_client import Neo4jClient
from .messages import MessageValidator
from .system_prompts import MAIN_SYSTEM_PROMPT
from .tools import retrieve_and_answer

logger = logging.getLogger(__name__)


class ChatState(MessagesState):
    """Enhanced state for LangGraph chatbot with tool support"""
    user_id: str = ""
    session_id: str = ""
    django_user: Optional[User] = None
    
    class Config:
        arbitrary_types_allowed = True

class ChatRequest:
    """Chat request data structure"""
    user_message: str
    user_id: str
    session_id: Optional[str] = None

    def __init__(self, user_message: str, user_id: str, session_id: Optional[str] = None):
        self.user_message = user_message
        self.user_id = user_id
        self.session_id = session_id

class ChatResponse:
    """Chat response data structure"""
    success: bool
    message: str
    data: Optional[Dict[str, Any]] = None
    session_id: Optional[str] = None
    task: Optional[str] = None
    confidence: Optional[float] = None
    timestamp: Optional[str] = None

    def __init__(self, success: bool, message: str, data: Optional[Dict[str, Any]] = None,
                 session_id: Optional[str] = None, task: Optional[str] = None,
                 confidence: Optional[float] = None, timestamp: Optional[str] = None):
        self.success = success
        self.message = message
        self.data = data
        self.session_id = session_id
        self.task = task
        self.confidence = confidence
        self.timestamp = timestamp


class Chatbot:
    """
    LangGraph-based chatbot with RAG tool integration
    """
    
    def __init__(self, llm=None, neo4j_client: Optional[Neo4jClient] = None, user: Optional[User] = None):
        self.llm = llm or get_openai_llm(model="gpt-4o-mini")
        self.neo4j_client = neo4j_client
        self.user = user
        
        # Initialize RAG components
        # TODO: Implement RAGAgent and ContentRetriever classes
        # self.rag_agent = RAGAgent(llm=self.llm, neo4j_client=neo4j_client)
        # self.content_retriever = ContentRetriever(neo4j_client=neo4j_client)
        
        # Attach components to the tool function for access
        # retrieve_and_answer._content_retriever = self.content_retriever
        # retrieve_and_answer._rag_agent = self.rag_agent
        
        # Build LangGraph workflow
        self.workflow = self._build_workflow()
        
        logger.info("LangGraphChatbot initialized with RAG tool")
    
    def _get_checkpointer(self):
        """Get the appropriate checkpointer based on availability"""
        try:
            # Get database connection string from Django settings
            db_settings = connection.settings_dict
            
            # Construct PostgreSQL connection string
            db_url = (
                f"postgresql://{db_settings['USER']}:{db_settings['PASSWORD']}"
                f"@{db_settings['HOST']}:{db_settings['PORT']}/{db_settings['NAME']}"
            )
            
            # Create PostgresSaver with connection
            checkpointer = PostgresSaver.from_conn_string(db_url)
            
            # Setup tables if they don't exist
            checkpointer.setup()
            
            logger.info("Using PostgresSaver for persistent checkpoints")
            return checkpointer
            
        except Exception as e:
            logger.error(f"Failed to initialize PostgresSaver: {e}")
            logger.info("Falling back to MemorySaver")
            return MemorySaver()
    
    def _build_workflow(self) -> CompiledStateGraph:
        """Build the LangGraph workflow with tool integration"""
        
        # Create state graph
        workflow = StateGraph(ChatState)
        
        # Create tool node with RAG tool
        tools = [retrieve_and_answer]
        tool_node = ToolNode(tools)
        
        # Add nodes
        workflow.add_node("agent", self._agent_node)
        workflow.add_node("tools", tool_node)
        workflow.add_node("save_to_database", self._save_to_database_node)
        
        # Set entry point
        workflow.set_entry_point("agent")
        
        # Add conditional edges for tool usage
        workflow.add_conditional_edges(
            "agent",
            tools_condition,
            {
                "tools": "tools",
                "__end__": "save_to_database"
            }
        )
        
        # After tools, go back to agent for final response
        workflow.add_edge("tools", "agent")
        workflow.add_edge("save_to_database", "__end__")
        
        # Compile with persistent storage
        checkpointer = self._get_checkpointer()
        return workflow.compile(checkpointer=checkpointer)
    
    def _agent_node(self, state: ChatState) -> Dict[str, Any]:
        """Main agent node that processes messages and decides whether to use tools"""
        
        try:
            # Get the latest user message
            user_message = None
            for msg in reversed(state["messages"]):
                if msg.type == "human":
                    user_message = msg.content
                    break
            
            if not user_message:
                return {
                    "messages": [AIMessage(content="I didn't receive a message. Could you please try again?")]
                }
            
            # Use single comprehensive system prompt
            system_message_content = MAIN_SYSTEM_PROMPT.format(
                user_id=state.user_id,
                session_id=state.session_id
            )
            
            # Check if we already have tool results in recent messages
            recent_tool_used = any(msg.type == "tool" for msg in state["messages"][-3:])
            
            if recent_tool_used:
                # We have tool results, generate final response based on tool output
                messages = [SystemMessage(content=system_message_content)] + state["messages"]
                response = self.llm.invoke(messages)
            else:
                # Prepare messages for LLM
                # Filter to only include human and AI messages (exclude tool messages for clean context)
                conversation_messages = [
                    msg for msg in state["messages"] 
                    if msg.type in ("human", "ai") and not getattr(msg, 'tool_calls', None)
                ]

                # First pass - LLM can decide whether to use tools based on the query
                llm_with_tools = self.llm.bind_tools([retrieve_and_answer])
                messages = [SystemMessage(content=system_message_content)] + conversation_messages
                response = llm_with_tools.invoke(messages)
            
            return {"messages": [response]}
            
        except Exception as e:
            logger.error(f"Agent node failed: {e}")
            return {
                "messages": [AIMessage(content="I'm sorry, I encountered an error. Please try again.")]
            }
    
    def _save_to_database_node(self, state: ChatState) -> Dict[str, Any]:
        """
        Save chat messages to Django database for application use.
        This is separate from PostgresSaver which handles LangGraph state persistence.
        """
        try:
            # Import here to avoid circular imports
            from apps.chatbot.models import ChatSession, ChatMessage
            
            # Get or create chat session
            session, created = ChatSession.objects.get_or_create(
                session_id=state.session_id,
                defaults={
                    'user_id': state.user_id,
                    'title': self._generate_session_title(state["messages"])
                }
            )
            
            # Get the latest messages that haven't been saved yet
            # Check what's already in database to avoid duplicates
            existing_count = ChatMessage.objects.filter(session=session).count()
            new_messages = state["messages"][existing_count:]
            
            # Save new messages
            with transaction.atomic():
                for message in new_messages:
                    # Skip tool messages as they're internal
                    if message.type == "tool":
                        continue
                        
                    # Determine metadata based on message context
                    metadata = {
                        "workflow_type": "langgraph_tool"
                    }
                    
                    # Check if this is a response that used tools
                    used_rag = False
                    tool_calls = False
                    confidence = None
                    task_type = None
                    
                    if message.type == "ai":
                        # Check for tool calls in this message
                        tool_calls = bool(getattr(message, 'tool_calls', None))
                        
                        # Check if there are recent tool messages before this AI message
                        message_index = state["messages"].index(message)
                        for i in range(max(0, message_index - 3), message_index):
                            if state["messages"][i].type == "tool":
                                used_rag = True
                                break
                        
                        confidence = 0.9 if used_rag else 0.7
                        task_type = "langgraph_rag_tool" if used_rag else "general_chat"
                    
                    ChatMessage.objects.create(
                        session=session,
                        message_type=message.type,
                        content=message.content,
                        used_rag_tool=used_rag,
                        tool_calls_made=tool_calls,
                        confidence=confidence,
                        task_type=task_type,
                        metadata=metadata
                    )
            
            # Update session timestamp
            session.save(update_fields=['updated_at'])
            
            logger.info(f"Saved {len(new_messages)} messages to database for session {state.session_id}")
            return {"messages": []}
            
        except Exception as e:
            logger.error(f"Failed to save messages to database: {e}")
            return {"messages": []}
    
    def _generate_session_title(self, messages: List) -> str:
        """
        Generate a title for the chat session based on the first user message
        """
        try:
            for message in messages:
                if message.type == "human":
                    # Take first 50 characters of the first user message
                    title = message.content[:47]
                    if len(message.content) > 47:
                        title += "..."
                    return title
            return "Chat Session"
        except Exception:
            return "Chat Session"
    
    def process_message(self, request: ChatRequest) -> ChatResponse:
        """
        Process a user message through the LangGraph workflow
        
        Args:
            user_message: User's input message
            user_id: User identifier
            session_id: Session identifier for conversation continuity
            
        Returns:
            Response dictionary with message and metadata
        """
        try:
            # Validate input
            is_valid, error_message = MessageValidator.validate_user_message(request.user_message)
            if not is_valid:
                return ChatResponse(
                    success=False,
                    message=f"Invalid input: {error_message}",
                    task='error',
                    timestamp=datetime.now().isoformat()
                )
            
            # Create session if needed
            session_id = request.session_id
            if not session_id:
                session_id = f"session_{request.user_id}_{int(time.time())}"
            
            # Create initial state
            initial_state = {
                "messages": [HumanMessage(content=request.user_message)],
                "user_id": request.user_id,
                "session_id": session_id,
                "django_user": self.user,
            }
            
            # Process through workflow
            config = {"configurable": {"thread_id": session_id}}
            result = self.workflow.invoke(initial_state, config=config)
            
            # Extract the final assistant message and check for tool usage
            assistant_message = None
            tool_used = False
            tool_calls_made = False
            
            for msg in reversed(result["messages"]):
                if msg.type == "ai" and not getattr(msg, 'tool_calls', None) and not assistant_message:
                    assistant_message = msg
                elif msg.type == "ai" and getattr(msg, 'tool_calls', None):
                    tool_calls_made = True
                elif msg.type == "tool":
                    tool_used = True
            
            if not assistant_message:
                raise ValueError("No assistant response generated")
            
            logger.info(f"Processed message for user {request.user_id}: tool_used={tool_used}")
            return ChatResponse(
                success=True,
                message=assistant_message.content,
                data={
                    "used_rag_tool": tool_used,
                    "tool_calls_made": tool_calls_made,
                    "workflow_type": "langgraph_tool"
                },
                session_id=session_id,
                task="langgraph_rag_tool",
                confidence=0.9 if tool_used else 0.7,
                timestamp=datetime.now().isoformat()
            )
            
        except Exception as e:
            logger.error(f"LangGraph workflow failed: {e}")
            error_session_id = session_id or f"session_{request.user_id}_{int(time.time())}"
            return ChatResponse(
                success=False,
                message=f"I'm sorry, I encountered an error: {e}",
                session_id=error_session_id,
                task='error',
                timestamp=datetime.now().isoformat()
            )