import time
import os

# Import Bluesky Modules
from sourcer import BonsaiSourcer
from planner import BonsaiPlanner
from curator import BonsaiCurator
from ranker import BonsaiRanker

# Import TikTok Modules
from tiktok_ingestion import fetch_tiktok_videos
from video_processor import VideoPreprocessor
from ai_engine import GeminiEngine  # File nÃ y chá»©a class GeminiEngine báº¡n Ä‘Ã£ sá»­a


def process_bluesky_flow(plan, sourcer, curator):
    """Quy trÃ¬nh xá»­ lÃ½ Text Post tá»« Bluesky"""
    print("\nğŸ”µ [MODE: BLUESKY POSTS] Äang kÃ­ch hoáº¡t...")
    raw_posts = []

    # 1. Sourcing
    print("   ğŸ“¡ Sourcing: Äang quÃ©t dá»¯ liá»‡u tá»« Bluesky...")
    for query in plan.get("search_queries", []):
        found_posts = sourcer.get_posts_by_query(query, limit=5)
        raw_posts.extend(found_posts)
        time.sleep(0.5)

    unique_posts = {p["uri"]: p for p in raw_posts}.values()
    print(f"   âœ… TÃ¬m tháº¥y {len(unique_posts)} bÃ i viáº¿t thÃ´.")

    # 2. Curating
    print("   âš–ï¸ Curating: AI Judge (Text) Ä‘ang cháº¥m Ä‘iá»ƒm...")
    curated_posts = []
    criteria = {
        "include_criteria": plan.get("include_criteria"),
        "exclude_criteria": plan.get("exclude_criteria"),
    }

    for post in unique_posts:
        rating = curator.rate_post(post["content"], criteria)
        post["curator_score"] = rating["score"]
        post["curator_reason"] = rating["reasoning"]

        print(
            f"   ğŸ“ [{rating['score']}/10] {post['content'][:30]}... -> {rating['reasoning']}"
        )

        if rating["score"] >= 4:
            curated_posts.append(post)

    return curated_posts


def process_tiktok_flow(plan, video_processor, gemini_engine):
    """Quy trÃ¬nh xá»­ lÃ½ Video tá»« TikTok"""
    print("\nğŸµ [MODE: TIKTOK VIDEOS] Äang kÃ­ch hoáº¡t...")

    # 1. Sourcing (Apify)
    print(f"   ğŸ“¡ Sourcing: Äang gá»i Apify Ä‘á»ƒ tÃ¬m video...")
    # Láº¥y danh sÃ¡ch tá»« khÃ³a tá»« Planner
    keywords = plan.get("search_queries", [])
    # Gá»i hÃ m tá»« tiktok_ingestion.py
    raw_videos = fetch_tiktok_videos(keywords, max_items=3)  # Demo nÃªn Ä‘á»ƒ Ã­t (3 video)

    processed_videos = []

    # 2. Processing & Curating (Gemini)
    print("   âš–ï¸ Curating: AI Judge (Multimodal) Ä‘ang xem video...")

    for vid in raw_videos:
        print(f"\n   â–¶ï¸ Äang xá»­ lÃ½ video: {vid['id']} ({vid['desc'][:30]}...)")

        # A. Download Video
        video_path = video_processor.download_video(vid)
        if not video_path:
            continue

        # B. Analyze with Gemini
        # Gemini tráº£ vá» JSON: {transcript_summary, visual_description, is_relevant_to_intent, reasoning}
        analysis = gemini_engine.analyze_video(video_path, post_text=vid["desc"])

        if analysis:
            # C. Mapping Data (Chuáº©n hÃ³a dá»¯ liá»‡u Ä‘á»ƒ khá»›p vá»›i Ranker)
            # Chuyá»ƒn Ä‘á»•i 'is_relevant' thÃ nh Ä‘iá»ƒm sá»‘ (Score)
            score = 8 if analysis.get("is_relevant_to_intent") else 2

            # Táº¡o object bÃ i viáº¿t chuáº©n
            processed_post = {
                "uri": vid["video_url"],  # DÃ¹ng Link Video lÃ m ID
                "author": vid["author"],
                "content": f"[VIDEO SUMMARY] {analysis.get('transcript_summary', '')}",  # Ná»™i dung lÃ  tÃ³m táº¯t cá»§a AI
                "original_desc": vid["desc"],  # LÆ°u caption gá»‘c Ä‘á»ƒ tham kháº£o
                "like_count": 0,  # Apify scraper Ä‘Ã´i khi khÃ´ng tráº£ vá» like, hoáº·c cáº§n map field khÃ¡c
                "repost_count": 0,
                "reply_count": 0,
                "created_at": "2025-01-01",  # Placeholder náº¿u khÃ´ng cÃ³ date
                "curator_score": score,
                "curator_reason": analysis.get("reasoning"),
                "visual_desc": analysis.get(
                    "visual_description"
                ),  # LÆ°u thÃªm mÃ´ táº£ hÃ¬nh áº£nh
            }

            print(f"      -> Äiá»ƒm: {score}/10 | LÃ½ do: {analysis.get('reasoning')}")

            # Lá»c rÃ¡c
            if score >= 4:
                processed_videos.append(processed_post)

            # XÃ³a file video táº¡m Ä‘á»ƒ tiáº¿t kiá»‡m á»• cá»©ng (Quan trá»ng!)
            try:
                os.remove(video_path)
            except:
                pass

    return processed_videos


def main():
    # --- 0. KHá»I Táº O Há»† THá»NG ---
    print("ğŸŒ± Äang khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng BONSAI...")

    # Common modules
    planner = BonsaiPlanner()
    ranker = BonsaiRanker()

    # Mode-specific modules (Lazy loading could be better but init here is fine)
    sourcer_bluesky = BonsaiSourcer()
    curator_text = BonsaiCurator()

    video_processor = VideoPreprocessor()
    gemini_engine = GeminiEngine()

    # --- INPUT ---
    print("\nğŸ›ï¸ CHá»ŒN CHáº¾ Äá»˜ HOáº T Äá»˜NG:")
    print("   [1] Posts (Bluesky - Text Focus)")
    print("   [2] Videos (TikTok - Multimodal Focus)")
    mode_choice = input("   > Nháº­p sá»‘ (1 hoáº·c 2): ").strip()

    mode = "tiktok" if mode_choice == "2" else "bluesky"

    user_intent = input(
        "\nâœï¸ Nháº­p Ã½ Ä‘á»‹nh cá»§a báº¡n (VD: I want to find xAI papers...): \n> "
    )
    if not user_intent:
        if mode == "bluesky":
            user_intent = "I want to find latest research papers about Explainable AI (xAI). No crypto."
        else:
            user_intent = "I want to find short tutorials explaining how Transformers work in AI. No dancing."
        print(f"(DÃ¹ng input máº·c Ä‘á»‹nh: {user_intent})")

    # --- BÆ¯á»šC 1: PLANNING ---
    print("\n" + "=" * 40)
    print("1ï¸âƒ£  PLANNING: Äang phÃ¢n tÃ­ch Ã½ Ä‘á»‹nh...")
    plan = planner.generate_plan(user_intent)

    if not plan:
        print("âŒ Lá»—i: KhÃ´ng thá»ƒ láº­p káº¿ hoáº¡ch.")
        return

    print(f"   âœ… Tá»« khÃ³a: {plan.get('search_queries')}")
    print(f"   âœ… Include: {plan.get('include_criteria')}")

    # --- BÆ¯á»šC 2 & 3: SOURCING & CURATING (Ráº½ nhÃ¡nh) ---
    print("\n" + "=" * 40)
    print(f"2ï¸âƒ£ & 3ï¸âƒ£ PROCESSING ({mode.upper()} MODE)...")

    final_candidates = []

    if mode == "bluesky":
        final_candidates = process_bluesky_flow(plan, sourcer_bluesky, curator_text)
    else:
        final_candidates = process_tiktok_flow(plan, video_processor, gemini_engine)

    print(f"\n   âœ… Thu Ä‘Æ°á»£c {len(final_candidates)} bÃ i/video cháº¥t lÆ°á»£ng.")

    # --- BÆ¯á»šC 4: RANKING ---
    print("\n" + "=" * 40)
    print("4ï¸âƒ£  RANKING: Äang sáº¯p xáº¿p láº¡i feed...")

    style = plan.get("ranking_preference", "balanced")
    final_feed = ranker.rank_posts(final_candidates, style=style)

    # --- OUTPUT ---
    print("\n" + "=" * 40)
    print(f"ğŸ“± YOUR PERSONALIZED FEED (Mode: {mode.upper()})")
    print("=" * 40)

    if not final_feed:
        print("ğŸ“­ Feed trá»‘ng!")
    else:
        for idx, post in enumerate(final_feed):
            print(f"\n[#{idx+1}] Äiá»ƒm xáº¿p háº¡ng: {post['final_score']}")
            print(f"ğŸ‘¤ TÃ¡c giáº£: {post['author']}")

            if mode == "tiktok":
                print(f"ğŸ¥ Ná»™i dung AI TÃ³m táº¯t: {post['content']}")
                print(f"ğŸ“ Caption gá»‘c: {post['original_desc']}")
            else:
                print(f"ğŸ“„ Ná»™i dung: {post['content']}")

            print(f"ğŸ’¡ xAI Insight: {post['curator_reason']}")
            print("-" * 20)


if __name__ == "__main__":
    main()
